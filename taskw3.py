# -*- coding: utf-8 -*-
"""TaskW3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wkqon86NU0pTlq52pzGPL78XlLazjwP3

### Web Scrubbing
"""

# Import required libraries for web scraping, data handling, and SSL warning suppression
import re, time
import requests
from bs4 import BeautifulSoup
import pandas as pd
import urllib3
from urllib3.exceptions import InsecureRequestWarning

urllib3.disable_warnings(InsecureRequestWarning)

# Define the target shop URL and custom headers
shop = "https://scrapeme.live/shop/"
headers = {
    "User-Agent": "Mozilla/5.0 (compatible; ShopScraper/1.0; +https://example.org/bot)"
}

# Get response from shop URL
shop_response = requests.get(shop, headers=headers, verify=False)

# Show response object
shop_response

# Parse HTML and show page title
shop_soup = BeautifulSoup(shop_response.text, 'html.parser')
print(shop_soup.title)

# Print formatted HTML
print(shop_soup.prettify())

# Get page title text
shop_soup.title.string

# Set shop URL and initialize variables
shop_url = shop
shop_rows = []
shop_page_num = 1

# Loop through shop pages
while True:
    print("Scraping list page:", shop_url)
    try:
        # Get page response
        r = requests.get(shop_url, headers=headers, timeout=15, verify=False)
        r.raise_for_status()
    except requests.exceptions.SSLError:
        r = requests.get(shop_url.replace("https://", "http://"), headers=headers, timeout=15, verify=False)
        r.raise_for_status()
    except requests.RequestException as e:
        print("Request failed:", e)
        break

    # Parse page
    soup = BeautifulSoup(r.text, "html.parser")

    # Find product items
    ul = soup.find("ul", class_="products")
    items = ul.find_all("li", class_="product") if ul else []
    print("Products on this page:", len(items))
    if not items:
        break

    for li in items:
        # name
        name_el = li.find("h2", class_="woocommerce-loop-product__title")
        shop_name = name_el.get_text(strip=True) if name_el else None

        # price
        price_wrap = li.find("span", class_="price")
        price_amount = price_wrap.find("span", class_="woocommerce-Price-amount") if price_wrap else None
        if price_amount:
            numeric = re.sub(r"[^\d.]", "", price_amount.get_text(strip=True))
            try:
                shop_price = float(numeric) if numeric else None
            except ValueError:
                shop_price = None
        else:
            shop_price = None

        # link and image
        link_el = li.find("a", class_="woocommerce-LoopProduct-link") or li.find("a", href=True)
        shop_product_url = link_el["href"] if link_el and link_el.has_attr("href") else None

        img_el = li.find("img", class_="wp-post-image")
        shop_image_url = img_el["src"] if img_el and img_el.has_attr("src") else None

        # categories/tags slugs
        li_classes = li.get("class", []) or []
        shop_cat_slugs = [c.replace("product_cat-", "") for c in li_classes if isinstance(c, str) and c.startswith("product_cat-")]
        shop_tag_slugs = [c.replace("product_tag-", "") for c in li_classes if isinstance(c, str) and c.startswith("product_tag-")]

        # product details
        shop_sku = None
        shop_categories = None
        shop_tags = None
        shop_stock_qty = None
        shop_stock_text = None
        shop_description = None

        if shop_product_url:
            try:
                # Get product page
                pr = requests.get(shop_product_url, headers=headers, timeout=15, verify=False)
                pr.raise_for_status()
            except requests.exceptions.SSLError:
                pr = requests.get(shop_product_url.replace("https://", "http://"), headers=headers, timeout=15, verify=False)
                pr.raise_for_status()
            except requests.RequestException:
                pr = None

            if pr is not None and pr.ok:
                ps = BeautifulSoup(pr.text, "html.parser")

                meta = ps.find("div", class_="product_meta")

                # SKU
                sku_el = meta.find("span", class_="sku") if meta else ps.find("span", class_="sku")
                shop_sku = sku_el.get_text(strip=True) if sku_el else None

                # categories
                cats = []
                posted_in = meta.find("span", class_="posted_in") if meta else None
                if posted_in:
                    for a in posted_in.find_all("a"):
                        t = a.get_text(strip=True) if a else None
                        if t:
                            cats.append(t)
                shop_categories = ", ".join(cats) if cats else (", ".join(shop_cat_slugs) if shop_cat_slugs else None)

                # tags
                tags = []
                tagged_as = meta.find("span", class_="tagged_as") if meta else None
                if tagged_as:
                    for a in tagged_as.find_all("a"):
                        t = a.get_text(strip=True) if a else None
                        if t:
                            tags.append(t)
                shop_tags = ", ".join(tags) if tags else (", ".join(shop_tag_slugs) if shop_tag_slugs else None)

                # stock
                stock_el = ps.find(lambda t: t and t.name and isinstance(t.get("class"), list) and "stock" in t.get("class", []))
                if stock_el:
                    txt = stock_el.get_text(" ", strip=True)
                    shop_stock_text = txt
                    m = re.search(r"(\d+)", txt)
                    if m:
                        try:
                            shop_stock_qty = int(m.group(1))
                        except ValueError:
                            shop_stock_qty = None

                # description
                short_el = ps.find("div", class_="woocommerce-product-details__short-description")
                long_el = ps.find(id="tab-description") or ps.find("div", class_="woocommerce-Tabs-panel--description")
                parts = []
                if short_el: parts.append(short_el.get_text(" ", strip=True))
                if long_el:  parts.append(long_el.get_text(" ", strip=True))
                shop_description = " ".join(parts) if parts else None

            time.sleep(0.25)

        # add row
        shop_rows.append([
            shop_name, shop_price, shop_product_url, shop_image_url,
            shop_sku, shop_categories, shop_tags,
            shop_stock_qty, shop_stock_text, shop_description, shop_page_num
        ])

    # pagination
    next_url = None
    nav = soup.find("nav", class_="woocommerce-pagination")
    if nav:
        for a in nav.find_all("a"):
            classes = a.get("class", []) or []
            if "next" in classes and "page-numbers" in classes and a.has_attr("href"):
                next_url = a["href"]
                break

    if not next_url:
        break

    shop_url = next_url
    shop_page_num += 1
    time.sleep(0.5)

# Create DataFrame from rows
shop_df = pd.DataFrame(
    shop_rows,
    columns=[
        "shop_name","shop_price",
        "shop_product_url","shop_image_url",
        "shop_sku","shop_categories","shop_tags",
        "shop_stock_qty","shop_stock_text",
        "shop_description","shop_page"
    ]
)

# Show first rows
shop_df.head()

# Export the DataFrame to a CSV file with UTF-8 encoding (without index column)
shop_df.to_csv("shop_products.csv", index=False, encoding="utf-8-sig")